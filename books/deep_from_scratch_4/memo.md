## sec 1

### 機械学習の分類と強化学習
- Supervised Learning
- Unsupervised Learning
- Self-Supervised Learning
- Reinforcement Learning

### バンディット問題
bandit = スロットマシンの別称

$$q(A)=\mathbb{E}[R|A]$$

A という行動を取った時の、R (Reward)の期待値で、行動価値と呼ぶ

q(A) は「真の行動価値」を表し、Q(A) は「推論値」を表す、という使い分けを行う

#### 大数の法則
サンプル平均は、真の値に近づく。無限回サンプリングした場合、そのサンプル平均は真の値に一致する。

#### プレイヤーの戦略
以下のトレードオフの関係にある
- これまで実際にプレイした結果を利用し、最善と思われるスロットマシンをプレイする（=greedy な行動）
- スロットマシンの価値を精度よく推論するために、さまざまなスロットマシンを試すこと
  - 「greedy でない行動」を試すこと（探索）で、より良い選択を見つけ出したい


上記トレードオフの関係、つまり、探索と活用のバランスをいかにとるか、そこが強化学習のアルゴリズムのきもとなる

- イプシロングリーディー法



