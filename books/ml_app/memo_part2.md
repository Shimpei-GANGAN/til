part 2: 機能するパイプラインの構築

## sec 3
モデルの調査、学習、評価は時間のかかるプロセスであるため、間違った方向に進むと ML では大きなコストになる。ML も他の多くのソフトウェアエンジニアリングと同様に、**できるだけ早く実用最小限の製品（MVP：Minimum Viable Product）**

### 最もシンプルな足場
２つのパイプラインのうち、推論パイプラインから始める。こうすることでプロトタイプを素早く構築でき、完全に動作するアプリケーションをすぐに確認できるという利点がある。

``` python
def clean_input(text):
    """
    :param text: ユーザの入力したテキスト
    :return: 非ascii文字を削除したサニタイズ済みテキスト
    """
    # 簡単にするために、最初はASCII文字だけを使う
    return str(text.encode().decode('ascii', error='ignore'))
```

モデルが成功していても、製品としては価値が出せていないことがよくある。


## sec 4
考案したワークフローとモデルが健全であることを検証したら、次はデータセットを深く掘り下げる。見つけた情報は、モデリングの決定に利用する。**多くの場合、データを十分に理解すると、パフォーマンスが大幅に向上する**

### データセットの反復処理
ML 製品を素早く構築するためには、モデル構築と評価を迅速に反復する。データセットはモデルを成功させるための核。そのため、**データの収集、準備、ラベルづけは、モデリングと同様に反復プロセスと考えるべき。**すぐに収集できる簡単なデータセットから始めて、学習内容に基づいて改善させる。

データを製品の一部として扱うことで、反復、変更、改善が可能になる（そしてそうするべき）。

モデルは既存のデータから傾向やパターンを抽出する手段として**のみ**機能する。モデルが活用できるほど十分に予測可能なパターンをデータが持っていることを確認すること（そして、明確な偏りを含んでいるかどうかを確認すること）は、データサイエンティスト（モデルサイエンティストではない）の基本的な仕事です！

### 初めてのデータセット探索
ほとんどのML問題では、データが多いほど良いモデルを作ることができますが、これは可能な限り大きなデータセットから始めるべき、という意味ではない。

ほとんどのエンジニアは、モデルのインパクトを過大評価し、データ作業の価値を過小評価しているので、この傾向を修正し、むしろデータの調査を偏重するような努力が常に必要。

#### データ品質規範
| 品質 | フォーマット | データ量と分布 |
| --- | --- | --- |
| 関連するフィールドが<br>空になることはないか | データには<br>幾つの前処理ステップが必要か | データは幾つあるか |
| 測定誤差の可能性はあるか | 本番環境でも同じように<br>前処理ができるか | １クラスあたりのデータ数は<br>いくつか。欠落はあるか |




## memo
- シリアル化
    - シリアル化（serialize）とは、プログラムの内部的なデータになんらかの変換を行い、連続的なデータに変換すること
    - 一般的に、データをファイルに保存したり、ネットワーク越しに転送する際に行う。

