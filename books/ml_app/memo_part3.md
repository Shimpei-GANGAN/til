part 3: モデルの反復

## sec 5

### 最も単純で適切なモデル
モデルが実装されたら、それがどのようにデータセットを活用しているかを調べて、理解する必要があります。そのためには、理解しやすいモデルでなければなりません

#### 理解しやすさ
モデルの説明可能性と解釈可能性は、モデルが行った予測の理由を明らかにする。

#### パターンからモデルへ

##### 特徴量のスケール
多くのモデルでは、小さい値よりも大きい値の特徴量が重用される。**最適化手法として勾配降下法を使用するNNのようなモデルでは、特徴量のスケールの違いが学習を不安定にすることがある**

特徴量の規模に関係なく、モデルが最も予測可能になるよう、特徴量を活用する。

このために、特徴量を前処理して平均が0, 分散が1になるようスケールを正規化する。

もう１つの解決策は、特徴量のスケールの違いに影響されないモデルを使用すること。最も一般的な実用例は、決定木、ランダムフォレスト、勾配ブースティング決定技など。XGBoostは、その堅牢性と実行速度から本番で一般的に使用されている勾配ブースティング決定木実装の１つ

##### パターンの組み合わせデータ
画像領域の問題に取り組む際には、**CNNがCNNが並進不変フィルター（translation-invariant filters）**を学習する能力により有用であることが証明されている。これは、位置に関係なく画像ないの局所的なパターンを抽出できることを意味する。

#### データリーク

##### サンプル汚染
データリークの一般的な原因は、ランダム性が利用されるところで発生する。小論文の評点を予測するモデルが、テストセットで完璧に近いパフォーマンスを発揮したとする。

このような難しい作業で非常にパフォーマンスの良いモデルは、**バグやデータリーク**が存在していることが多いため、綿密に調査する。ML分野のマーフィーの法則として、「**テストデータに対するモデルのパフォーマンスの良さと、パイプラインにエラーのある可能性は比例する**」と言われている。

この例では、ほとんどの学生が複数の小論文を書いていたため、データをランダムに分割することで同じ学生の小論文が学習セットとテストセットの両方に存在することになった。これにより、モデルは学生を識別する特徴量を取得し、その情報を使用して正確な予測をしていた。

もしこの予測器を本番の環境へデプロイすると、これまでみたことのない学生のスコアを予測することができず、過去の小論文のスコアを予測するだけになってしまう。

このデータリークを解決するために、論文ではなく学生に対してデータの分割を行なった。これは、各学生は学習セット、または検証セットのどちらかのみに含まれることを意味する。


> 特に驚くほど高いパフォーマンスを発揮したモデルは、必ず調査を行わなければならない

``` python
from sklearn.model_selection import GroupShuffleSplit

def get_split_by_author(
    posts, author_id_column="OwnerUserId", test_size=0.3, random_state=40
):
    """
    学習/テストデータに分割する
    全てのauthorが分割の一方にのみ含まれることを保証する
    :param posts: 全てのラベル付き投稿
    :param author_id_column: author_idの含まれるカラム名
    :param test_size: テストに割り当てる割合
    :param random_state: ランダムシート
    """
    splitter = GroupShuffleSplit(
        n_splits=1, test_size=test_size, random_state=random_state
    )
    splits = splitter.split(posts, groups=posts[author_id_column])
    return next(splits)
```

### モデルの評価

#### データと予測の対比
混同行列により、モデルが特定のクラスでは特に成功しているか、他のクラスでは機能していないかが一目でわかる。これは、多くの異なるクラスを持つデータセットや、不均衡なクラスを持つデータセットで特に有用！

#### ROC曲線（ROC Curve）
二項分類問題では、受信者動作特性（ROC: Receiver Operating Characteristic）曲線も非常に有用。ROC 曲線は、真陽性率（TPR: True Positive Rate）を偽陽性率（FPR: False Positive Rate）の関数としてプロットしたもの。

#### ブラックボックス説明可能性ツール
特徴量が複雑になると、特徴量の重要度を解釈するのが難しくなる。NNのような複雑なモデルの一部には、学習した特徴量の重要度を明らかにできないものもある。このような状況では、モデルの内部動作とは無関係にモデルの予測を説明しようとするブラックボックス説明可能性ツールを活用するのが一般的。

LIME や SHAP など。



