## BERT による自然言語処理入門
- [Github](https://github.com/stockmarkteam/bert-book)
- Transformers：BERT で処理を行うためのライブラリ
- PyTorch Lightning：学習や性能評価を効率的に行うためのライブラリ

## sec 1

### NLP
- 基礎的な技術
    - 形態素解析
    - 言語モデル
        - 文章の自然さを確立で表現する
    - 固有表現抽出
    - 文章の類似度比較
- 応用的な技術
    - 文章分類
    - 文章生成
    - 文章校正

### ML
ML の一般的な流れ

- データからタスクを解くのに有用な特徴量を抽出する
- 抽出した特徴をモデルに入力し、その出力から問題を解く

**深層学習**においては、特徴量抽出とその後のモデルによる処理が１つのモデルで完結する「**end-to-end**」と呼ばれる形態をとっており、その中で特徴量は自動的に抽出されるようになっている！

### ML による NLP
ニューラル言語モデルの特徴の１つは、文章や単語を「密なベクトル（ほとんどがゼロのベクトルではない）」に変換できるということ。**文章や単語を密なベクトルとして表現したもの**は**分散表現**と呼ばれる。ニューラル言語モデルから得られる分散表現は何らかの形で単語や文章の意味を反映していると考えられる。そのため、ニューラル言語モデルから得られる分散表現はデータの有用な特徴量として用いられる。

ニューラル言語モデルは、特徴量抽出器としての役割を担っている。

### BERT
BERT は 2018 年に Google から発表されたニューラル言語モデル。文脈を考慮した分散表現を作成できる。

例えば、BERTから得られる単語の分散表現は、同じ単語でも文脈（周りの単語）が変わると、それに応じて異なる値を取る。Attention により、離れた位置でも適切に取り入れることができる。

